# %%[markdown]

"""
# Projeto: Dashboard waze - geral

Data: 22 junho 2021

Dataset: Traffic jams: traffic slowdown information generated by the service based on a
user’s location and speed. "Data provided by Waze App. Learn more at Waze.com".

Conteúdo: Leitura do Feed e criar arquivo .csv.

Metodologia da estrutura dos dados: Foram foram feitas associações espaciais para os
bairros da cidade, separação entre rodovias, área urbana e rural.
Também foi feita a adição de uma grade hexagonal de 250x250metros, a fim de
manter referência a seção viária.
"""

# %%

import datetime
from calendar import monthrange
from enum import unique
import os
import numpy as np
import pandas as pd
import geopandas as gpd
import json
# import seaborn as sns
# import matplotlib.pyplot as plt

# pd.set_option('display.max_columns', 45)

# %%

# localização dados
dir_atual = os.getcwd()

local_base = '/geo/www/mapas/waze'

local_base_feed = f'{local_base}/resultados'
local_dados_aux = f'{local_base}/dados'
local_saida_dados = f'{local_base}/dados_exportados'
pastas_base_feed = os.listdir(local_base_feed)


# datas
data_hj = datetime.date.today()
hoje = data_hj.strftime('%Y-%m-%d')

now = datetime.datetime.now()

meses_levantamento = [now.strftime('%Y-%m')]
for _ in range(0, 2):
    now = now.replace(day=1) - datetime.timedelta(days=1)
    meses_levantamento.append(now.strftime('%Y-%m'))

# %%
# carregar dados pasta feed


def pegar_mes(ano, mes, tipo):
    dias_mes = range(monthrange(ano, mes)[1]+1)[1:]
    dias = []
    for d in dias_mes:
        dias.append(f'{ano}-{mes:02}-{d:02}_{tipo}')

    dados_mes = []
    for f in dias:
        try:
            dados_mes.append(gpd.read_file(
                f'{local_base_feed}/{ano}/{tipo}/{f}.json'))
        except:
            print(f'dia {f} não encontrado')
    return gpd.GeoDataFrame(pd.concat(dados_mes, ignore_index=True),
                            crs=dados_mes[0].crs)

# %%
# levantar dados


levantamento_jams = []

for mes in meses_levantamento:
    dt_mes = pegar_mes(int(mes[0:4]), int(mes[5:7]), 'jams')
    levantamento_jams.append(dt_mes)

gdf = gpd.GeoDataFrame(
    pd.concat(levantamento_jams, ignore_index=True), crs=levantamento_jams[0].crs)

print('união realizada')

# %%
# classe intervalohora

gdf['intervalohora'] = pd.cut(gdf['timestamp'].str[11:13].astype('int'),
                              [0, 6, 9, 12, 15, 18, 21, 24],
                              labels=['0-5', '6-8', '9-11', '12-14',
                                      '15-17', '18-20', '21-24'],
                              right=False)

gdf['dtdate'] = gdf['timestamp'].str.slice(0, 10)

gdf['dia'] = gdf['timestamp'].str[8:10].astype('int')

gdf['hora'] = gdf['timestamp'].str[11:13].astype('int')

gdf['mes'] = gdf['timestamp'].str[5:7].astype('int')

gdf['mes_ext'] = gdf['timestamp'].str[5:7].map({'01': 'Jan.', '02': 'Fev.',
                                                '03': 'Mar.', '04': 'Abr.',
                                                '05': 'Maio', '06': 'Jun.',
                                                '07': 'Jul.', '08': 'Ago.',
                                                '09': 'Set.', '10': 'Out.',
                                                '11': 'Nov.', '12': 'Dez.'})

# %%
# organizar colunas

gdf = gdf.drop(columns=['country', 'segments', 'city', 'type',
                        'turnType', 'blockingAlertUuid', 'startNode'])

gdf['speed'] = np.round(gdf['speed'], decimals=2)
gdf['speedKMH'] = np.round(gdf['speedKMH'], decimals=2)

# %%
# articulação malha hexagonal

grade_hex_itj = gpd.read_file(f'{local_dados_aux}/grade_itj.shp')

gdf = gpd.overlay(
    gdf,
    grade_hex_itj,
    how='intersection')

# %%
# comprimento cortado pela malha hexagonal, em metros

gdf = gdf.to_crs(epsg=31982)
gdf['hexlength'] = gdf.length.apply(np.ceil).astype(int)

# %%
# delay cortado pela malha hexagonal, em m/s

gdf['hexdelay'] = (gdf['delay'] * gdf['hexlength']) / gdf['length']
gdf['hexdelay'] = gdf['hexdelay'].apply(np.ceil).astype(int)
gdf['hexdelay'] = np.where(gdf['delay'] == -1, -1, gdf['hexdelay'])

# %%
# regiões
# grupo_a = ['Centro', 'Fazenda', 'Vila Operária']
# grupo_b = ['Fazendinha', 'Praia Brava de Itajaí']
# grupo_c = ['Nossa Senhora das Graças', 'Ressacada', 'Dom Bosco', 'Carvalho']
# grupo_d = ['Barra do Rio', 'Cordeiros', 'São João', 'São Judas']
# grupo_e = ['São Vicente', 'Cidade Nova']
# grupo_f = ['demais regiões']


def regioes(x):
    if (x in ['Centro', 'Fazenda', 'Vila Operária']):
        return "Centro, Fazenda, Vila Operária"
    elif (x in ['Fazendinha', 'Praia Brava de Itajaí']):
        return "Fazendinha, Praia Brava de Itajaí"
    elif (x in ['Nossa Senhora das Graças', 'Ressacada', 'Dom Bosco', 'Carvalho']):
        return "Nossa Senhora das Graças, Ressacada, Dom Bosco, Carvalho"
    elif (x in ['Barra do Rio', 'Cordeiros', 'São João', 'São Judas']):
        return "Barra do Rio, Cordeiros, São João, São Judas"
    elif (x in ['São Vicente', 'Cidade Nova']):
        return "São Vicente, Cidade Nova"
    else:
        return "demais regiões"


gdf['m_regioes'] = gdf['nomebairro'].apply(regioes)

# %%
# limpeza

gdf = gdf.join(gdf['centroid'].str.split(',', 1, expand=True).rename(
    columns={0: 'lat', 1: 'long'}))

gdf = gdf[['nomebairro', 'm_regioes', 'regiao', 'uuid', 'delay', 'hexdelay', 'level',
           'street', 'intervalohora', 'orientacao', 'timestamp', 'dtdate', 'dia', 'dia_semana',
           'mes', 'mes_ext', 'hora', 'length', 'hexlength', 'speedKMH', 'speed',
           'roadType', 'endNode', 'lat', 'long']]

# %%[markdown]
# Descrição colunas
#
# nome          |descrição
# --------------|----
# codhexagon*   |código da célula hexagonal que compõe a grade espacial cobrindo a cidade.
# nomebairro*   |nome do bairro a que a seção pertence
# regiao*       |área no município ('urbana', 'rodovias', 'rural')
# uuid          |id da ocorrência
# delay         |atraso em relação ao fluxo normal, segundos (bloqueio do tráfego, -1)
# hexdelay*     |atraso relativo ao trecho do congestionamento sobre a célula hexagonal
# level         |nível de congestionamento (0 = nenhum 5 = bloqueio no tráfego)
# dia_semana*   |dia da semana da ocorrência
# street        |denominação da via segundo a base do google
# intervalohora*|intervalos em horas ('0-5','5-8','8-11','11-14','14-17','17-20','20-24')
# orientacao*   |direção do fluxo de tráfego
# timestamp*    |carimbo de data
# length        |comprimento do congestionamento em metros
# hexlength*    |comrimento relativo ao trecho sobre a célula hexagonal
# speedKMH*     |velocidade em Km/h
# speed         |velocidade em m/s
# roadType**    |tipo de via segundo a tabela tipo de via**
# endNode       |nome da via que pertence ao cruzamento mais próximo
# centroid*     |coordenadas do centróide da célula hexagonal, em wgs84(4326)
#
# * coluna criada na etapa de coleta/armazenamento
#
# ** Tabela roadType:
#
# código |tipo
# -------|----
# 1      |Streets
# 2      |Primary Street
# 3      |Freeways
# 4      |Ramps
# 5      |Trails
# 6      |Primary
# 7      |Secondary
# 8, 14  |4X4 Trails
# 15     |Ferry crossing
# 9      |Walkway
# 10     |Pedestrian
# 11     |Exit
# 16     |Stairway
# 17     |Private road
# 18     |Railroads
# 19     |Runway/Taxiway
# 20     |Parking lot road
# 21     |Service road

# %%
# Progressão regiões

progressao_m_regioes = \
    gdf.groupby(['m_regioes', 'dia', 'mes',
                 'mes_ext'], as_index=False)['hexdelay']\
    .mean().sort_values(['m_regioes', 'mes', 'dia'],
                        ignore_index=True)

# progressao_m_regioes.loc[(progressao_m_regioes['m_regioes'] == "Centro', Fazenda")].head()
# plt.figure(figsize=(15, 5))
# plt.xticks(rotation=90)
# sns.lineplot(data=progressao_m_regioes, x='dia',
#              y='hexdelay', hue='mes_ext')

# %%
# exportar arquivos webmap

# prog_dia_semana
progressao_m_regioes.to_csv(
    f'{local_saida_dados}/progressao_m_regioes.tsv', sep='\t', index=False)

# %%
# média pelos 5 piores dias do mês

unique_regioes = gdf['m_regioes'].unique()

regioes_dic = {elem: pd.DataFrame for elem in unique_regioes}

for key in regioes_dic.keys():
    regioes_dic[key] = gdf[['m_regioes', 'mes_ext',
                            'dia', 'hexdelay']][gdf['m_regioes'] == key]

# %%
#

unique_meses = gdf['mes_ext'].unique()

regioes_mes_valores = []

for i, (key, value) in enumerate(regioes_dic.items()):
    reg_mes = {'regiao': key, 'meses': []}

    for mes in unique_meses:
        m_mes = \
            value[:][gdf['mes_ext'] == mes].groupby(['dia'],
                                                    as_index=False)['hexdelay'].mean()\
            .sort_values(['hexdelay'],
                         ignore_index=True,
                         ascending=False).head(5)
        delaymes = np.rint(m_mes['hexdelay'].mean()).astype(int)
        reg_mes['meses'].append(f'{mes}: {delaymes}')

    regioes_mes_valores.append(reg_mes)

# %%

with open(f'{local_saida_dados}/regioes_mes_valores.json', 'w') as saida:
    json.dump(regioes_mes_valores, saida)
